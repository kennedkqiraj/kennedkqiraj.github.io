[
  {
    "title": "Preferential Origin Automation — On AG",
    "brand": "on",
    "logo": "assets/on_logo.png",
    "desc": "End-to-end automation of preferential origin assessment: extract rules from FTAs with NLP, embed and store in ChromaDB for fast retrieval, and run an app workflow to determine origin per product.",
    "bullets": [
      "Rule extraction from FTA PDFs using NLP models; clean, segment, and normalize clauses.",
      "Embeddings + ChromaDB: vectorize rules and save for low-latency semantic retrieval.",
      "Pipeline: identify applicable rule per HS code → read requirements → component analysis.",
      "Threshold calculation (value/weight/process rules) → final origin determination.",
      "Explains decisions with Gemini for transparent, human-readable rationales."
    ],
    "tags": [
      "Preferential Origin",
      "FTA",
      "NLP",
      "Embeddings",
      "ChromaDB",
      "Gemini",
      "Google Cloud",
      "Flask",
      "HS Code",
      "Trade Compliance"
    ]
  },
  {
    "title": "Comments Analytics for NZZ (IBM watsonx)",
    "brand": "ibm",
    "logo": "assets/ibm.png",
    "desc": "Auto-categorizes, summarizes, and gauges sentiment in reader comments—surfacing trending topics and points of disagreement. Built on IBM watsonx with guidance from IBM Zürich.",
    "bullets": [
      "Auto-tag & summarize comment streams",
      "Insights: topics, themes, sentiment, controversy",
      "Word-clouds for quick visual scanning",
      "Orchestration: IBM Cloud Object Storage → watsonx Orchestrate → Discovery / watsonx.ai → database & updated metadata",
      "Uses Intelligent Document Processing; simple analyst-friendly UI"
    ],
    "tags": [
      "LLMs",
      "watsonx.ai",
      "Discovery",
      "Orchestrate",
      "IBM Cloud Object Storage",
      "NLP",
      "Sentiment",
      "Python",
      "Word-clouds",
      "Automation"
    ]
  },
  {
    "title": "GenAI Email Automation — RAG + Llama",
    "brand": "llama",
    "logo": "assets/llama.png",
    "desc": "Drafts customer-reply emails by pulling context from past threads and internal docs. A RAG pipeline retrieves the right snippets; a Llama-based model generates tone-aware drafts with a human in the loop.",
    "bullets": [
      "Indexed prior email threads and internal knowledge; chunked and embedded for fast retrieval.",
      "For each inbound email, retrieved top-K relevant history to assemble a focused context window.",
      "Generated drafts via prompt templates with tone and format controls.",
      "Human-in-the-loop review/approve workflow before sending.",
      "Logged queries, retrieved chunks, and outputs for iterative improvement."
    ],
    "tags": [
      "RAG",
      "Llama",
      "LLM",
      "Embeddings",
      "Retrieval",
      "Vector DB",
      "Email Automation",
      "Python"
    ]
  }
]
